{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(img1, img2, savefig=False):\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches2to1 = flann.knnMatch(des2,des1,k=2)\n",
    "\n",
    "    matchesMask_ratio = [[0,0] for i in xrange(len(matches2to1))]\n",
    "    match_dict = {}\n",
    "    for i,(m,n) in enumerate(matches2to1):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            matchesMask_ratio[i]=[1,0]\n",
    "            match_dict[m.trainIdx] = m.queryIdx\n",
    "\n",
    "    good = []\n",
    "    recip_matches = flann.knnMatch(des1,des2,k=2)\n",
    "    matchesMask_ratio_recip = [[0,0] for i in xrange(len(recip_matches))]\n",
    "\n",
    "    for i,(m,n) in enumerate(recip_matches):\n",
    "        if m.distance < 0.7*n.distance: # ratio\n",
    "            if m.queryIdx in match_dict and match_dict[m.queryIdx] == m.trainIdx: #reciprocal\n",
    "                good.append(m)\n",
    "                matchesMask_ratio_recip[i]=[1,0]\n",
    "\n",
    "\n",
    "\n",
    "    if savefig:\n",
    "        draw_params = dict(matchColor = (0,255,0),\n",
    "                           singlePointColor = (255,0,0),\n",
    "                           matchesMask = matchesMask_ratio_recip,\n",
    "                           flags = 0)\n",
    "        img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,recip_matches,None,**draw_params)\n",
    "\n",
    "        plt.figure(),plt.xticks([]),plt.yticks([])\n",
    "        plt.imshow(img3,)\n",
    "        plt.savefig(\"feature_matching.png\",bbox_inches='tight')\n",
    "\n",
    "    return ([ kp1[m.queryIdx].pt for m in good ],[ kp2[m.trainIdx].pt for m in good ])\n",
    "\n",
    "# Warp an image from cartesian coordinates (x, y) into cylindrical coordinates (theta, h)\n",
    "# Returns: (image, mask)\n",
    "# Mask is [0,255], and has 255s wherever the cylindrical images has a valid value.\n",
    "# Masks are useful for stitching\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "#     im = cv2.imread(\"myimage.jpg\",0) #grayscale\n",
    "#     h,w = im.shape\n",
    "#     f = 700\n",
    "#     K = np.array([[f, 0, w/2], [0, f, h/2], [0, 0, 1]]) # mock calibration matrix\n",
    "#     imcyl = cylindricalWarpImage(im, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylindricalWarpImage(img1, K, savefig=False):\n",
    "    f = K[0,0]\n",
    "\n",
    "    im_h,im_w = img1.shape\n",
    "\n",
    "    # go inverse from cylindrical coord to the image\n",
    "    # (this way there are no gaps)\n",
    "    cyl = np.zeros_like(img1)\n",
    "    cyl_mask = np.zeros_like(img1)\n",
    "    cyl_h,cyl_w = cyl.shape\n",
    "    x_c = float(cyl_w) / 2.0\n",
    "    y_c = float(cyl_h) / 2.0\n",
    "    for x_cyl in np.arange(0,cyl_w):\n",
    "        for y_cyl in np.arange(0,cyl_h):\n",
    "            theta = (x_cyl - x_c) / f\n",
    "            h     = (y_cyl - y_c) / f\n",
    "\n",
    "            X = np.array([math.sin(theta), h, math.cos(theta)])\n",
    "            X = np.dot(K,X)\n",
    "            x_im = X[0] / X[2]\n",
    "            if x_im < 0 or x_im >= im_w:\n",
    "                continue\n",
    "\n",
    "            y_im = X[1] / X[2]\n",
    "            if y_im < 0 or y_im >= im_h:\n",
    "                continue\n",
    "\n",
    "            cyl[int(y_cyl),int(x_cyl)] = img1[int(y_im),int(x_im)]\n",
    "            cyl_mask[int(y_cyl),int(x_cyl)] = 255\n",
    "\n",
    "\n",
    "    if savefig:\n",
    "        plt.imshow(cyl, cmap='gray')\n",
    "        plt.savefig(\"cyl.png\",bbox_inches='tight')\n",
    "\n",
    "    return (cyl,cyl_mask)\n",
    "\n",
    "# Calculate the geometric transform (only affine or homography) between two images,\n",
    "# based on feature matching and alignment with a robust estimator (RANSAC).\n",
    "\n",
    "# Returns: (M, pts1, pts2, mask)\n",
    "# Where: M    is the 3x3 transform matrix\n",
    "#        pts1 are the matched feature points in image 1\n",
    "#        pts2 are the matched feature points in image 2\n",
    "#        mask is a binary mask over the lists of points that selects the transformation inliers\n",
    "\n",
    "# Usage example:\n",
    "#     im1 = cv2.imread(\"image1.jpg\", 0)\n",
    "#     im2 = cv2.imread(\"image2.jpg\", 0)\n",
    "#     (M, pts1, pts2, mask) = getTransform(im1, im2)\n",
    "\n",
    "#     # for example: transform im1 to im2's plane\n",
    "#     # first, make some room around im2\n",
    "#     im2 = cv2.copyMakeBorder(im2,200,200,500,500, cv2.BORDER_CONSTANT)\n",
    "#     # then transform im1 with the 3x3 transformation matrix\n",
    "#     out = cv2.warpPerspective(im1, M, (im1.shape[1],im2.shape[0]), dst=im2.copy(), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "#     plt.imshow(out, cmap='gray')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTransform(src, dst, method='affine'):\n",
    "    pts1,pts2 = feature_matching(src,dst)\n",
    "\n",
    "    src_pts = np.float32(pts1).reshape(-1,1,2)\n",
    "    dst_pts = np.float32(pts2).reshape(-1,1,2)\n",
    "\n",
    "    if method == 'affine':\n",
    "        M, mask = cv2.estimateAffine2D(src_pts, dst_pts, cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "        M = np.append(M, [[0,0,1]], axis=0)\n",
    "\n",
    "    if method == 'homography':\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "    return (M, pts1, pts2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# ================ Perspective Warping ==============\n",
    "# ===================================================\n",
    "def Perspective_warping(img1, img2, img3):\n",
    "\t\n",
    "\t# Write your codes here\n",
    "\toutput_image = img1 # This is dummy output, change it to your output\n",
    "\t\n",
    "\t# Write out the result\n",
    "\toutput_name = sys.argv[5] + \"output_homography.png\"\n",
    "\tcv2.imwrite(output_name, output_image)\n",
    "\t\n",
    "\treturn True\n",
    "\t\n",
    "def Bonus_perspective_warping(img1, img2, img3):\n",
    "\t\n",
    "\t# Write your codes here\n",
    "\toutput_image = img1 # This is dummy output, change it to your output\n",
    "\t\n",
    "\t# Write out the result\n",
    "\toutput_name = sys.argv[5] + \"output_homography_lpb.png\"\n",
    "\tcv2.imwrite(output_name, output_image)\n",
    "\t\n",
    "\treturn True\n",
    "\n",
    "# ===================================================\n",
    "# =============== Cynlindrical Warping ==============\n",
    "# ===================================================\n",
    "def Cylindrical_warping(img1, img2, img3):\n",
    "\t\n",
    "\t# Write your codes here\n",
    "\toutput_image = img1 # This is dummy output, change it to your output\n",
    "\t\n",
    "\t# Write out the result\n",
    "\toutput_name = sys.argv[5] + \"output_cylindrical.png\"\n",
    "\tcv2.imwrite(output_name, output_image)\n",
    "\t\n",
    "\treturn True\n",
    "\n",
    "def Bonus_cylindrical_warping(img1, img2, img3):\n",
    "\t\n",
    "\t# Write your codes here\n",
    "\toutput_image = img1 # This is dummy output, change it to your output\n",
    "\t\n",
    "\t# Write out the result\n",
    "\toutput_name = sys.argv[5] + \"output_cylindrical_lpb.png\"\n",
    "\tcv2.imwrite(output_name, output_image)\n",
    "\t\n",
    "\treturn True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/conda_1486588158526/work/opencv-3.1.0/modules/python/src2/cv2.cpp:163: error: (-215) The data should normally be NULL! in function allocate\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2a954fa9f2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input2.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-6efb81467d92>\u001b[0m in \u001b[0;36mfeature_matching\u001b[0;34m(img1, img2, savefig)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msearch_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# or pass empty dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mflann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlannBasedMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmatches2to1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdes1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmatchesMask_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches2to1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/conda_1486588158526/work/opencv-3.1.0/modules/python/src2/cv2.cpp:163: error: (-215) The data should normally be NULL! in function allocate\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"input1.png\")\n",
    "img2 = cv2.imread(\"input2.png\")\n",
    "\n",
    "feature_matching(img1, img2, savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
